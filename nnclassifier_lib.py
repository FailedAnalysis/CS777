# -*- coding: utf-8 -*-
"""classifier_lib.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TWv0zydSzl42hliNx4EQLNg5CwKmFNqq
"""

import argparse
import os
import json
from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler
from pyspark.ml.classification import MultilayerPerceptronClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql import DataFrame

DEFAULT_TEST_SPLIT_RATIO = 0.2
DEFAULT_RANDOM_STATE = 321
LABEL_COLUMN = 'label'
CELL_COLUMN = 'cell'
PARTITION_FACTOR = 2
DEFAULT_NUM_PARTITIONS = 200

def preprocess_data(spark: SparkSession, input_paths: list, num_partitions: int) -> tuple[DataFrame, DataFrame]:
    print("Starting data preprocessing...")
    df = spark.read.csv(input_paths, header=True, inferSchema=True)
    print(f"Initial dataframe loaded with {df.count()} rows and {len(df.columns)} columns.")
    print(f"Repartitioning to {num_partitions} partitions...")
    df = df.repartition(num_partitions)
    print(f"DataFrame repartitioned to {df.rdd.getNumPartitions()} partitions.")
    for col_name in (LABEL_COLUMN, CELL_COLUMN):
        if col_name not in df.columns:
            print(f"Error: Required column '{col_name}' not found in input data.")
            raise ValueError(f"Required column '{col_name}' not found.")
    feature_cols = [c for c in df.columns if c not in (LABEL_COLUMN, CELL_COLUMN)]
    print(f"Identified {len(feature_cols)} feature columns.")
    print(f"Indexing label column '{LABEL_COLUMN}'...")
    idx_model = StringIndexer(inputCol=LABEL_COLUMN, outputCol="label_indexed").fit(df)
    df = idx_model.transform(df)
    label_classes = idx_model.labels
    print(f"Indexed labels: {label_classes}")
    print("Assembling feature vector...")
    df = VectorAssembler(inputCols=feature_cols, outputCol="features_vector").transform(df)
    print("Scaling features...")
    df = MinMaxScaler(inputCol="features_vector", outputCol="features_scaled").fit(df).transform(df)
    processed = df.select("features_scaled", "label_indexed")
    print(f"Splitting data into train ({1 - DEFAULT_TEST_SPLIT_RATIO:.2f}) and test ({DEFAULT_TEST_SPLIT_RATIO:.2f}) sets...")
    train_df, test_df = processed.randomSplit(
        [1 - DEFAULT_TEST_SPLIT_RATIO, DEFAULT_TEST_SPLIT_RATIO],
        seed=DEFAULT_RANDOM_STATE
    )
    print(f"Train set size: {train_df.count()} rows")
    print(f"Test set size: {test_df.count()} rows")
    print("Preprocessing complete. Returning train and test DataFrames.")
    return train_df, test_df

def train_model(spark: SparkSession, train_df: DataFrame, test_df: DataFrame, evaluation_output_path: str):
    print("\nStarting model training...")
    label_index_col = "label_indexed"
    features_col = "features_scaled"
    input_size = len(train_df.select(features_col).first()[0])
    num_classes = train_df.select(label_index_col).distinct().count()
    print(f"Input feature size: {input_size}")
    print(f"Number of classes: {num_classes}")
    layers = [input_size, 128, 64, num_classes]
    print(f"MLP layers defined as: {layers}")
    mlp = MultilayerPerceptronClassifier(
        layers=layers,
        maxIter=100,
        blockSize=64,
        seed=DEFAULT_RANDOM_STATE,
        tol=1e-4,
        solver='l-bfgs',
        featuresCol=features_col,
        labelCol=label_index_col
    )
    print("MLP classifier initialized.")
    print("Training model...")
    model = mlp.fit(train_df)
    print("Model training complete.")
    print("Making predictions on the test set...")
    predictions = model.transform(test_df)
    print("Evaluating model...")
    evaluator = MulticlassClassificationEvaluator(
        labelCol=label_index_col,
        predictionCol="prediction"
    )
    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: "accuracy"})
    f1 = evaluator.evaluate(predictions, {evaluator.metricName: "f1"})
    weightedPrecision = evaluator.evaluate(predictions, {evaluator.metricName: "weightedPrecision"})
    weightedRecall = evaluator.evaluate(predictions, {evaluator.metricName: "weightedRecall"})
    print(f"Test Accuracy = {accuracy:.4f}")
    print(f"Test F1 Score = {f1:.4f}")
    print(f"Test Weighted Precision = {weightedPrecision:.4f}")
    print(f"Test Weighted Recall = {weightedRecall:.4f}")
    print(f"Saving evaluation results to {evaluation_output_path}...")
    try:
        results_data = [
            (f"Test Accuracy: {accuracy:.4f}",),
            (f"Test F1 Score: {f1:.4f}",),
            (f"Test Weighted Precision: {weightedPrecision:.4f}",),
            (f"Test Weighted Recall: {weightedRecall:.4f}",)
        ]
        results_df = spark.createDataFrame(results_data, ["result"])
        results_df.write.mode("overwrite").text(evaluation_output_path)
        print("Evaluation results saved successfully using Spark.")
    except Exception as e:
        print(f"Error saving evaluation results to {evaluation_output_path} using Spark: {e}")
        import traceback
        traceback.print_exc()
    print("Model training and evaluation complete.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Gene Expression Data Processing and Model Training Pipeline (Single File Input)")
    parser.add_argument(
        "input_file",
        nargs=1,
        help="Path to the single input CSV data file."
    )
    parser.add_argument(
        "evaluation_output_path",
        help="Path to save the model evaluation results (e.g., accuracy). This should be a directory path for Spark write."
    )
    parser.add_argument(
        "--num_partitions",
        type=int,
        default=DEFAULT_NUM_PARTITIONS,
        help=f"Desired number of partitions after initial data loading (default: {DEFAULT_NUM_PARTITIONS})."
    )
    args = parser.parse_args()
    spark = SparkSession.builder.appName("GeneExpressionSingleFilePipeline").getOrCreate()
    print("Spark session created.")
    try:
        train_df, test_df = preprocess_data(spark, args.input_file, args.num_partitions)
        train_model(spark, train_df, test_df, args.evaluation_output_path)
    except Exception as e:
        print(f"An error occurred during the pipeline execution: {e}")
        import traceback
        traceback.print_exc()
    finally:
        spark.stop()
        print("Spark session stopped.")